{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Decimal to Binary.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_wpb61BmYNKO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### This is a python implementation to convert a digit classification neural network classification's decimal output to bitwise representation.\n",
        "\n",
        "### Magic is in last layer."
      ]
    },
    {
      "metadata": {
        "id": "2dXNgo8wYeSa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Question (http://neuralnetworksanddeeplearning.com/chap1.html#exercise_513527)\n",
        "\n",
        "```\n",
        "There is a way of determining the bitwise representation of a digit by adding an extra layer to the three-layer network above. The extra layer converts the output from the previous layer into a binary representation, as illustrated in the figure below.\n",
        "\n",
        "Find a set of weights and biases for the new output layer. Assume that the first 3 layers of neurons are such that the correct output in the third layer (i.e., the old output layer) has activation at least 0.99, and incorrect outputs have activation less than 0.01.\n",
        "```\n",
        "\n",
        "![alt text](http://neuralnetworksanddeeplearning.com/images/tikz13.png)"
      ]
    },
    {
      "metadata": {
        "id": "JtOEObDIiOIL",
        "colab_type": "code",
        "outputId": "62c62793-1eb1-49aa-f25b-282ec133c7f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NEURAL NETWORKS AND DEEP LEARNING by Michael Nielsen\n",
        "\n",
        "Chapter 1\n",
        "\n",
        "http://neuralnetworksanddeeplearning.com/chap1.html#exercise_513527\n",
        "\n",
        "Exercise:\n",
        "\n",
        "There is a way of determining the bitwise representation of a digit by adding an extra layer to the three-layer network above. The extra layer converts the output from the previous layer into a binary representation, as illustrated in the figure below. Find a set of weights and biases for the new output layer. Assume that the first 3 layers of neurons are such that the correct output in the third layer (i.e., the old output layer) has activation at least 0.99, and incorrect outputs have activation less than 0.01.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "'''\n",
        "Represent    Old                     New\n",
        "0            1 0 0 0 0 0 0 0 0 0     0 0 0 0 \n",
        "1            0 1 0 0 0 0 0 0 0 0     0 0 0 1 \n",
        "2            0 0 1 0 0 0 0 0 0 0     0 0 1 0 \n",
        "\n",
        "3            0 0 0 1 0 0 0 0 0 0     0 0 1 1 \n",
        "4            0 0 0 0 1 0 0 0 0 0     0 1 0 0 \n",
        "5            0 0 0 0 0 1 0 0 0 0     0 1 0 1 \n",
        "\n",
        "6            0 0 0 0 0 0 1 0 0 0     0 1 1 0 \n",
        "7            0 0 0 0 0 0 0 1 0 0     0 1 1 1 \n",
        "8            0 0 0 0 0 0 0 0 1 0     1 0 0 0 \n",
        "\n",
        "9            0 0 0 0 0 0 0 0 0 1     1 0 0 1\n",
        "\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return(1/(1+np.exp(-x)))\n",
        "\n",
        "\n",
        "def new_representation(activation_vector):\n",
        "    a_0 = np.sum(w_0 * activation_vector)\n",
        "    a_1 = np.sum(w_1 * activation_vector)\n",
        "    a_2 = np.sum(w_2 * activation_vector)\n",
        "    a_3 = np.sum(w_3 * activation_vector)\n",
        "\n",
        "    return a_3, a_2, a_1, a_0\n",
        "\n",
        "\n",
        "def new_repr_binary_vec(new_representation_vec):\n",
        "    sigmoid_op = np.apply_along_axis(sigmoid, 0, new_representation_vec)\n",
        "    return (sigmoid_op > 0.5).astype(int)\n",
        "\n",
        "\n",
        "w_0 = np.full(10, -1, dtype=np.int8)\n",
        "w_0[[1, 3, 5, 7, 9]] = 1\n",
        "w_1 = np.full(10, -1, dtype=np.int8)\n",
        "w_1[[2, 3, 6, 7]] = 1\n",
        "w_2 = np.full(10, -1, dtype=np.int8)\n",
        "w_2[[4, 5, 6, 7]] = 1\n",
        "w_3 = np.full(10, -1, dtype=np.int8)\n",
        "w_3[[8, 9]] = 1\n",
        "\n",
        "activation_vec = np.full(10, 0.01, dtype=np.float)\n",
        "# correct number is 5\n",
        "activation_vec[5] = 0.99\n",
        "\n",
        "new_representation_vec = new_representation(activation_vec)\n",
        "#print(new_representation_vec)\n",
        "# (-1.04, 0.96, -1.0, 0.98)\n",
        "print(new_repr_binary_vec(new_representation_vec))\n",
        "# [0 1 0 1]\n",
        "\n",
        "# if you wish to convert binary vector to int\n",
        "b = new_repr_binary_vec(new_representation_vec)\n",
        "print(b.dot(2**np.arange(b.size)[::-1]))\n",
        "# 5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 1]\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}