{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dog_classification_12_perc_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tajain07/neural-network-playground/blob/master/dog_classification_12_perc_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K_V2BQ1xKFDM",
        "colab_type": "code",
        "outputId": "d8df16ee-21f2-4668-dfb2-f6ad15fa4870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
        "!sudo apt-get install unzip\n",
        "!unzip -q dogImages.zip\n",
        "!mkdir data\n",
        "!mv dogImages data/dog_images"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-27 07:49:42--  https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
            "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.24.177\n",
            "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.24.177|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1132023110 (1.1G) [application/zip]\n",
            "Saving to: ‘dogImages.zip’\n",
            "\n",
            "dogImages.zip       100%[===================>]   1.05G  21.9MB/s    in 50s     \n",
            "\n",
            "2019-01-27 07:50:33 (21.5 MB/s) - ‘dogImages.zip’ saved [1132023110/1132023110]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l1KAbHKMRU1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "9e54bcf4-fafb-4b57-d765-8908047d242e"
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/tajain07/neural-network-playground/raw/master/project-dog-classification_cnn/model_scratch_12_perc.pt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-27 07:48:32--  https://github.com/tajain07/neural-network-playground/raw/master/project-dog-classification_cnn/model_scratch_12_perc.pt\n",
            "Resolving github.com (github.com)... 140.82.118.4, 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/tajain07/neural-network-playground/master/project-dog-classification_cnn/model_scratch_12_perc.pt [following]\n",
            "--2019-01-27 07:48:32--  https://raw.githubusercontent.com/tajain07/neural-network-playground/master/project-dog-classification_cnn/model_scratch_12_perc.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53768009 (51M) [application/octet-stream]\n",
            "Saving to: ‘model_scratch_12_perc.pt’\n",
            "\n",
            "model_scratch_12_pe 100%[===================>]  51.28M   236MB/s    in 0.2s    \n",
            "\n",
            "2019-01-27 07:48:33 (236 MB/s) - ‘model_scratch_12_perc.pt’ saved [53768009/53768009]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_urht3PaKFDW",
        "colab_type": "code",
        "outputId": "74d6f0cb-1e10-46c2-9672-e483847a64ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FHesjD8mKFDb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from PIL import ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "\n",
        "### TODO: Write data loaders for training, validation, and test sets\n",
        "## Specify appropriate transforms, and batch_sizes\n",
        "\n",
        "num_workers = 1\n",
        "batch_size = 64\n",
        "\n",
        "data_dir = \"data/dog_images\"\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(size=(240,240)), \n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "                                \n",
        "#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "\n",
        "train_data = datasets.ImageFolder(data_dir + \"/train\", transform=transform)\n",
        "\n",
        "validation_data = datasets.ImageFolder(data_dir + \"/valid\", transform=transform)\n",
        "\n",
        "test_data = datasets.ImageFolder(data_dir + \"/test\", transform=transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                            num_workers=num_workers,shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(validation_data, batch_size=16, \n",
        "      \n",
        "                                           num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4, \n",
        "                                           num_workers=num_workers)\n",
        "\n",
        "\n",
        "loaders_scratch = {}\n",
        "loaders_scratch['train'] = train_loader\n",
        "loaders_scratch['valid'] = valid_loader\n",
        "loaders_scratch['test'] = test_loader                                                            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3c4i10o7KFDf",
        "colab_type": "code",
        "outputId": "5812a21b-7177-4e4c-a8c5-ccafa8639c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    ### TODO: choose an architecture, and complete the class\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        ## Define layers of a CNN\n",
        "        \n",
        "        # sees -  (240 x 240 x 3)\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        # sees -  (120 x 120 x 32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=0)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        # sees -  (59 x 59 x 64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        # out -  (28 x 28 x 128\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.fc1 = nn.Linear(28 * 28 * 128, 133)\n",
        "        \n",
        "        self.dropout_dense = nn.Dropout(0.25)\n",
        "        \n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        ## Define forward behavior\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.bn1(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "       \n",
        "        #x = self.dropout_cnn(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.bn2(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        #print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.bn3(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        x = x.view(-1, 28 * 28 * 128)\n",
        "        x = self.dropout_dense(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "#-#-# You so NOT have to modify the code below this line. #-#-#\n",
        "\n",
        "# instantiate the CNN\n",
        "model_scratch = Net()\n",
        "\n",
        "print(model_scratch)\n",
        "# move tensors to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model_scratch.cuda()\n",
        "    #input = input.cuda() \n",
        "    model_scratch = nn.DataParallel(model_scratch)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=100352, out_features=133, bias=True)\n",
            "  (dropout_dense): Dropout(p=0.25)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FXpAOD3lKFDj",
        "colab_type": "code",
        "outputId": "0f88ca12-c159-40c9-de48-7ecfd97c6884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "### TODO: select loss function\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "\n",
        "### TODO: select optimizer\n",
        "#optimizer_scratch = optim.Adam(model_scratch.parameters(), lr = 0.00001)\n",
        "\n",
        "optimizer_scratch = optim.Adam([\n",
        "    {'params': model_scratch.parameters(), 'weight_decay': 0.1, 'amsgrad': True}\n",
        "], lr=0.00001)\n",
        "\n",
        "#optimizer_scratch = optim.Adam([\n",
        "#    {'params': model_scratch.parameters(), 'amsgrad': True}\n",
        "#])\n",
        "\n",
        "print(optimizer_scratch)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: True\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 1e-05\n",
            "    weight_decay: 0.1\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MXZyIanrKFDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        #train_loss_old = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            #print(target.shape)\n",
        "            #print(output.shape)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            #print(batch_idx)\n",
        "            #train_loss_old += loss.item()*data.size(0)\n",
        "            if(batch_idx % 10 == 0):\n",
        "              print(\"batch_idx {} , train_loss {}\".format(batch_idx, train_loss))\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            \n",
        "        #train_loss_old = train_loss_old/len(loaders['train'].dataset)\n",
        "        \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "              valid_loss_min,\n",
        "              valid_loss))\n",
        "          \n",
        "          torch.save(model.state_dict(), save_path)\n",
        "          valid_loss_min = valid_loss\n",
        "    # return trained model\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZkAhNP4Sqg6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "#model_scratch = train(20, loaders_scratch, model_scratch, optimizer_scratch, \n",
        "#                      criterion_scratch, use_cuda, 'model_scratch.pt')\n",
        "\n",
        "\n",
        "# load the model that got the best validation accuracy\n",
        "model_scratch.load_state_dict(torch.load('model_scratch_12_perc.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9c0rh58kKFDr",
        "colab_type": "code",
        "outputId": "cc8a1128-4469-420f-cc9c-6ed963b7c9c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 3.946966\n",
            "\n",
            "\n",
            "Test Accuracy: 12% (102/836)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}