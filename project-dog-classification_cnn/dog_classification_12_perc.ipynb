{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dog_classification_12_perc.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K_V2BQ1xKFDM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
        "!sudo apt-get install unzip\n",
        "!unzip -q dogImages.zip\n",
        "!mkdir data\n",
        "!mv dogImages data/dog_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_urht3PaKFDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b592ba6c-3cd4-4903-c383-5542c15272b4"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FHesjD8mKFDb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from PIL import ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "\n",
        "### TODO: Write data loaders for training, validation, and test sets\n",
        "## Specify appropriate transforms, and batch_sizes\n",
        "\n",
        "num_workers = 1\n",
        "batch_size = 64\n",
        "\n",
        "data_dir = \"data/dog_images\"\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(size=(240,240)), \n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "                                \n",
        "#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "\n",
        "train_data = datasets.ImageFolder(data_dir + \"/train\", transform=transform)\n",
        "\n",
        "validation_data = datasets.ImageFolder(data_dir + \"/valid\", transform=transform)\n",
        "\n",
        "test_data = datasets.ImageFolder(data_dir + \"/test\", transform=transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                            num_workers=num_workers,shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(validation_data, batch_size=16, \n",
        "      \n",
        "                                           num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4, \n",
        "                                           num_workers=num_workers)\n",
        "\n",
        "\n",
        "loaders_scratch = {}\n",
        "loaders_scratch['train'] = train_loader\n",
        "loaders_scratch['valid'] = valid_loader\n",
        "loaders_scratch['test'] = test_loader                                                            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3c4i10o7KFDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4159f804-4e6f-468a-9f9c-92a9dd928053"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    ### TODO: choose an architecture, and complete the class\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        ## Define layers of a CNN\n",
        "        \n",
        "        # sees -  (240 x 240 x 3)\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        # sees -  (120 x 120 x 32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=0)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        # sees -  (59 x 59 x 64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        # out -  (28 x 28 x 128\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.fc1 = nn.Linear(28 * 28 * 128, 133)\n",
        "        \n",
        "        self.dropout_dense = nn.Dropout(0.25)\n",
        "        \n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        ## Define forward behavior\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.bn1(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "       \n",
        "        #x = self.dropout_cnn(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.bn2(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        #print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.bn3(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        x = x.view(-1, 28 * 28 * 128)\n",
        "        x = self.dropout_dense(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "#-#-# You so NOT have to modify the code below this line. #-#-#\n",
        "\n",
        "# instantiate the CNN\n",
        "model_scratch = Net()\n",
        "\n",
        "print(model_scratch)\n",
        "# move tensors to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model_scratch.cuda()\n",
        "    #input = input.cuda() \n",
        "    model_scratch = nn.DataParallel(model_scratch)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=100352, out_features=133, bias=True)\n",
            "  (dropout_dense): Dropout(p=0.25)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FXpAOD3lKFDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "aa1528a6-305a-46d7-8c1e-150fe05b5f80"
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "### TODO: select loss function\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "\n",
        "### TODO: select optimizer\n",
        "#optimizer_scratch = optim.Adam(model_scratch.parameters(), lr = 0.00001)\n",
        "\n",
        "optimizer_scratch = optim.Adam([\n",
        "    {'params': model_scratch.parameters(), 'weight_decay': 0.1, 'amsgrad': True}\n",
        "], lr=0.00001)\n",
        "\n",
        "#optimizer_scratch = optim.Adam([\n",
        "#    {'params': model_scratch.parameters(), 'amsgrad': True}\n",
        "#])\n",
        "\n",
        "print(optimizer_scratch)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: True\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 1e-05\n",
            "    weight_decay: 0.1\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MXZyIanrKFDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        #train_loss_old = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            #print(target.shape)\n",
        "            #print(output.shape)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            #print(batch_idx)\n",
        "            #train_loss_old += loss.item()*data.size(0)\n",
        "            if(batch_idx % 10 == 0):\n",
        "              print(\"batch_idx {} , train_loss {}\".format(batch_idx, train_loss))\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            \n",
        "        #train_loss_old = train_loss_old/len(loaders['train'].dataset)\n",
        "        \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "              valid_loss_min,\n",
        "              valid_loss))\n",
        "          \n",
        "          torch.save(model.state_dict(), save_path)\n",
        "          valid_loss_min = valid_loss\n",
        "    # return trained model\n",
        "    return model\n",
        "\n",
        "\n",
        "# train the model\n",
        "#model_scratch = train(20, loaders_scratch, model_scratch, optimizer_scratch, \n",
        "#                      criterion_scratch, use_cuda, 'model_scratch.pt')\n",
        "\n",
        "\n",
        "# load the model that got the best validation accuracy\n",
        "model_scratch.load_state_dict(torch.load('model_scratch_12_perc.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9c0rh58kKFDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "25a385ae-cd06-4d87-9610-b8ff1c55732a"
      },
      "cell_type": "code",
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 3.946966\n",
            "\n",
            "\n",
            "Test Accuracy: 12% (102/836)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5hcwDt8TKFDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}